{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0f02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
      "(506, 13)\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston # 보스턴 집값 데이터셋\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "print(boston_dataset.DESCR) # 데이터셋 정보 확인\n",
    "# 506개의 데이터가 있음 13개의 입력변수, 14번째 속성이 목표변수. 집 가격임\n",
    "\n",
    "print(boston_dataset.feature_names) # 속성 이름들\n",
    "\n",
    "print(boston_dataset.data) # 입력변수들이 행렬로 나옴\n",
    "print(boston_dataset.data.shape) # 506개의 행과 13개의 열, 506개의 데이터와 13개의 속성\n",
    "\n",
    "print(boston_dataset.target) # 506개의 집 가격, 목표변수가 나옴\n",
    "print(boston_dataset.target.shape) # 차원이 506인 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db5a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
      "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
      "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
      "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
      "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
      "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "0       15.3  396.90   4.98  \n",
      "1       17.8  396.90   9.14  \n",
      "2       17.8  392.83   4.03  \n",
      "3       18.7  394.63   2.94  \n",
      "4       18.7  396.90   5.33  \n",
      "..       ...     ...    ...  \n",
      "501     21.0  391.99   9.67  \n",
      "502     21.0  396.90   9.08  \n",
      "503     21.0  396.90   5.64  \n",
      "504     21.0  393.45   6.48  \n",
      "505     21.0  396.90   7.88  \n",
      "\n",
      "[506 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# 이제 데이터프레임으로 보자!\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "print(x)\n",
    "\n",
    "# 입력변수 한 개일 때만 봐보자!\n",
    "x = x[['AGE']] # 열 하나만 갖고오기\n",
    "\n",
    "# 목표변수 설정\n",
    "y = pd.DataFrame(boston_dataset.target, columns=['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f593c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 1)\n",
      "(102, 1)\n",
      "(404, 1)\n",
      "(102, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 입력변수(x)와 목표변수(y) 넘겨주고, 전체 데이터 중에 20퍼센트만 test에 사용, 나머지는 train에 사용하라는 의미\n",
    "# random_state는 test를 어떻게 고를지 정하는 마라미터임, 옵셔널이라서 안 줘도 됨\n",
    "# 안 주면 실행할 때마다 새롭게 매번 랜덤한 test를 고르게 됨 (지금처럼 정수 넘겨주면 매번 같은 데이터 고름, 아무 정수 넣어도 됨)\n",
    "# 4개의 값을 반환해서 각각 들어갈 것을 설정했다.\n",
    "# 모두 판다스 데이터 프레임이다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5) \n",
    "\n",
    "# 20대 80으로 나뉨\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb73dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12402883]]\n",
      "[31.04617413]\n",
      "67.8462187008521\n",
      "8.236881612652455\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런으로 선형회귀 사용\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(model.coef_) # 모델의 정보중 세타1 값\n",
    "print(model.intercept_) # 세타0의 값\n",
    "\n",
    "y_test_prediction = model.predict(x_test) # 테스트 데이터셋에 대한 예측값\n",
    "\n",
    "# 평균 제곱 오차 구하기\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_test_prediction)) # 평균 제곱 오차\n",
    "print(mean_squared_error(y_test, y_test_prediction) ** 0.5) # 평균 제곱근 오차, 루트 씌우면 되는데, 0.5제곱과 같으니 0.5제곱 하기\n",
    "# 위 모델로 집값 구하면 약 8천달러 정도의 오차가 있다고 보면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131f4a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.30799852e-01  4.94030235e-02  1.09535045e-03  2.70536624e+00\n",
      "  -1.59570504e+01  3.41397332e+00  1.11887670e-03 -1.49308124e+00\n",
      "   3.64422378e-01 -1.31718155e-02 -9.52369666e-01  1.17492092e-02\n",
      "  -5.94076089e-01]]\n",
      "[37.91248701]\n",
      "20.86929218377074\n",
      "4.5682920423032\n"
     ]
    }
   ],
   "source": [
    "# 다중 선형회귀\n",
    "X = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "X\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.coef_) # 세타0을 제외한 모든 세타 값\n",
    "print(model.intercept_) # 세타0의 값, 손실을 최대한 적게하는 세타 값\n",
    "\n",
    "y_test_prediction = model.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_test_prediction)) # 평균 제곱 오차\n",
    "print(mean_squared_error(y_test, y_test_prediction) ** 0.5) # 평균 제곱근 오차\n",
    "# 위 모델로 집값 구하면 약 4천달러 정도의 오차가 있다고 보면 됨\n",
    "# 입력변수 여러 개 하니 오차가 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692ffff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 105)\n",
      "['1', 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'CRIM^2', 'CRIM ZN', 'CRIM INDUS', 'CRIM CHAS', 'CRIM NOX', 'CRIM RM', 'CRIM AGE', 'CRIM DIS', 'CRIM RAD', 'CRIM TAX', 'CRIM PTRATIO', 'CRIM B', 'CRIM LSTAT', 'ZN^2', 'ZN INDUS', 'ZN CHAS', 'ZN NOX', 'ZN RM', 'ZN AGE', 'ZN DIS', 'ZN RAD', 'ZN TAX', 'ZN PTRATIO', 'ZN B', 'ZN LSTAT', 'INDUS^2', 'INDUS CHAS', 'INDUS NOX', 'INDUS RM', 'INDUS AGE', 'INDUS DIS', 'INDUS RAD', 'INDUS TAX', 'INDUS PTRATIO', 'INDUS B', 'INDUS LSTAT', 'CHAS^2', 'CHAS NOX', 'CHAS RM', 'CHAS AGE', 'CHAS DIS', 'CHAS RAD', 'CHAS TAX', 'CHAS PTRATIO', 'CHAS B', 'CHAS LSTAT', 'NOX^2', 'NOX RM', 'NOX AGE', 'NOX DIS', 'NOX RAD', 'NOX TAX', 'NOX PTRATIO', 'NOX B', 'NOX LSTAT', 'RM^2', 'RM AGE', 'RM DIS', 'RM RAD', 'RM TAX', 'RM PTRATIO', 'RM B', 'RM LSTAT', 'AGE^2', 'AGE DIS', 'AGE RAD', 'AGE TAX', 'AGE PTRATIO', 'AGE B', 'AGE LSTAT', 'DIS^2', 'DIS RAD', 'DIS TAX', 'DIS PTRATIO', 'DIS B', 'DIS LSTAT', 'RAD^2', 'RAD TAX', 'RAD PTRATIO', 'RAD B', 'RAD LSTAT', 'TAX^2', 'TAX PTRATIO', 'TAX B', 'TAX LSTAT', 'PTRATIO^2', 'PTRATIO B', 'PTRATIO LSTAT', 'B^2', 'B LSTAT', 'LSTAT^2']\n",
      "[[-2.55720147e-07 -5.09146958e+00 -1.65753983e-01 -5.97358604e+00\n",
      "   2.43179271e+01  1.65180559e+02  2.19910116e+01  1.03167123e+00\n",
      "  -5.66895775e+00  3.22443249e+00 -1.10055942e-02  5.35127787e+00\n",
      "  -4.81524409e-02  7.53109325e-01  2.16774682e-03  2.69938772e-01\n",
      "   5.87901385e-01  2.41731932e+00 -2.52413199e-02  8.92859572e-02\n",
      "  -5.18832420e-03 -5.77807152e-02  3.55602049e-01 -3.86092282e-02\n",
      "   5.43572101e-01 -3.18134358e-04  2.40035425e-02 -7.48850220e-04\n",
      "  -7.16133310e-03 -1.06886010e-01 -1.27782609e+00  2.50137719e-02\n",
      "   1.14111417e-04 -1.25254119e-02 -4.68024813e-03  6.05725185e-04\n",
      "  -8.57873132e-03  1.85030053e-03 -4.64730601e-03  3.08484808e-02\n",
      "  -2.09065897e-01  1.30035723e+00  3.13497405e-01  6.72540164e-04\n",
      "   7.51823883e-02 -7.38014886e-03  4.23364348e-04 -6.72155117e-03\n",
      "   6.42107774e-03 -5.32275093e-03  2.43179249e+01 -1.84845896e+01\n",
      "  -6.89090796e+00  3.60375828e-02  3.05451225e+00 -4.09746374e-01\n",
      "   2.34143012e-02 -8.47140007e-01  2.67079534e-02 -4.67786369e-01\n",
      "  -4.67850812e+01  3.64543351e+00 -6.00214489e-01  1.59316284e+01\n",
      "  -9.85012970e-01  1.34091848e-01 -1.19204901e+01 -3.52741122e-02\n",
      "   1.49910251e+00  1.61796865e-01 -5.59710757e-02 -2.01415694e-02\n",
      "  -1.48173641e-01 -1.44084743e-02 -5.43970810e-01 -2.51829107e-03\n",
      "  -2.23180151e-01  1.04437606e-04 -1.11866477e-02  1.76080422e-02\n",
      "  -5.61733228e-04  7.89859009e-04 -7.29621881e-04 -6.91541692e-03\n",
      "   5.10744891e-01 -9.97148046e-02 -5.10129116e-03 -1.89041938e-01\n",
      "  -7.59517251e-03  1.03720290e-01 -1.40678180e-01  7.67704651e-03\n",
      "  -1.15933963e-01 -9.65920565e-04 -4.55543664e-02 -5.15985543e-05\n",
      "   6.37266840e-03 -1.20248657e-04 -1.90119503e-04 -1.35160919e-02\n",
      "   9.14979704e-03 -2.02259709e-04 -1.93102592e-05 -7.46677274e-04\n",
      "   9.84814764e-03]]\n",
      "[-141.89855579]\n",
      "10.217789027082967\n",
      "3.1965276515436196\n"
     ]
    }
   ],
   "source": [
    "# 다항회귀를 할 때 가상의 열(속성)을 만들어야하는데, sklearn이 모두 다 해준다!\n",
    "from sklearn.preprocessing import PolynomialFeatures # 다항 속성\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(2) # 몇 차 함수인지 작성, 2차함수로 작성함.\n",
    "polynomial_data = polynomial_transformer.fit_transform(boston_dataset.data) # 다항 변형기(다항 회귀를 위해 가공)\n",
    "\n",
    "print(polynomial_data.shape) # 506행 105열(13개 열을 조합하고 가상의 열을 추가해서 총 105개가 됨)\n",
    "polynomial_feature_names = polynomial_transformer.get_feature_names(boston_dataset.feature_names)\n",
    "print(polynomial_feature_names) # 가능한 거의 모든 2차 조합이 다 있다, 곱하거나 제곱하거나 등등.., 1은 bias임\n",
    "\n",
    "X = pd.DataFrame(polynomial_data, columns=polynomial_feature_names)\n",
    "X\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.coef_) # 세타0을 제외한 모든 세타 값\n",
    "print(model.intercept_) # 세타0의 값\n",
    "\n",
    "y_test_prediction = model.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_test_prediction)) # 평균 제곱 오차\n",
    "print(mean_squared_error(y_test, y_test_prediction) ** 0.5) # 평균 제곱근 오차\n",
    "# 위 모델로 집값 구하면 약 3천달러 정도의 오차가 있다고 보면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413dfe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 0 2 1 0 2 0 1 1 2 2 2 0 0 2 2 0 0 1 2 0 1 1 2 1 1 1 2]\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 분류 데이터셋 iris\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "# print(iris_data.DESCR) # 꽃받침(sepal)과 꽃잎(petal) 길이와 너비\n",
    "\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = pd.DataFrame(iris_data.target, columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) \n",
    "y_train = y_train.values.ravel() # 데이터 타입을 데이터프레임에서 넘파이 배열로 변경해줌\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# solver는 모델을 최적화할 때 어떤 알고리즘을 쓸지 결정하는 것이다.\n",
    "# max_iter는 최적화할 때 해당 과정을 몇 번 반복할지 결정하는 것이다. (경사하강법에서도 손실을 줄이기 위해 반복하니..)\n",
    "# 2000번 설정했다고 해서 2000번 돌진 않음, 그전에 최적화 됐다 판단하면 알아서 멈춤\n",
    "# 모두 옵셔널이라서 안 적어도 되긴 함\n",
    "model = LogisticRegression(solver='saga', max_iter=2000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict(X_test))\n",
    "\n",
    "print(model.score(X_test, y_test)) # 모델 평가, 93% 확률로 제대로 분류했다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c1b57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.482808</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.368479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.173481</td>\n",
       "      <td>0.177357</td>\n",
       "      <td>0.161937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Height       Weight          Age\n",
       "count  1340.000000  1340.000000  1340.000000\n",
       "mean      0.482808     0.422586     0.368479\n",
       "std       0.173481     0.177357     0.161937\n",
       "min       0.000000     0.000000     0.000000\n",
       "25%       0.333333     0.316456     0.238095\n",
       "50%       0.481481     0.392405     0.333333\n",
       "75%       0.611111     0.569620     0.476190\n",
       "max       1.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nba_player_of_the_week_df = pd.read_csv('./NBA_player_of_the_week.csv')\n",
    "\n",
    "nba_player_of_the_week_df.head()\n",
    "\n",
    "nba_player_of_the_week_df.describe() # 각 열에 있는 데이터에 대한 통계 확인\n",
    "\n",
    "height_weight_age_df = nba_player_of_the_week_df[['Height CM','Weight KG', 'Age']]\n",
    "nba_player_of_the_week_df.head()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler() # min-max normalization로 데이터를 0과 1사이로 바꿔주는 도구\n",
    "normalized_data = scaler.fit_transform(height_weight_age_df)\n",
    "normalized_data\n",
    "\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=['Height', 'Weight', 'Age']) # Normalizeation한 데이터를 갖는 새 데이터프레임 생성\n",
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e08cfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Survived  Pclass  \\\n",
       "0           0         0       3   \n",
       "1           1         1       1   \n",
       "2           2         1       3   \n",
       "3           3         1       1   \n",
       "4           4         0       3   \n",
       "\n",
       "                                                Name   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         A/5 21171   7.2500   NaN           0         1           0   \n",
       "1          PC 17599  71.2833   C85           1         0           1   \n",
       "2  STON/O2. 3101282   7.9250   NaN           1         0           0   \n",
       "3            113803  53.1000  C123           1         0           0   \n",
       "4            373450   8.0500   NaN           0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic_df = pd.read_csv('./titanic.csv')\n",
    "titanic_df.head()\n",
    "\n",
    "titanic_sex_embarked = titanic_df[['Sex', 'Embarked']] # 성별과 탑승지\n",
    "titanic_sex_embarked.head()\n",
    "\n",
    "one_hot_encoded_df = pd.get_dummies(titanic_sex_embarked) # 판다스로 쉽게 one-hot encoding, 파라미터로 변환하고 싶은 데이터프레임 념겨주면 됨\n",
    "one_hot_encoded_df.head()\n",
    "\n",
    "\n",
    "# 전체 데이터프레임에서 원하는 열들만 One-hot Encoding\n",
    "one_hot_encoded_df = pd.get_dummies(data=titanic_df, columns=['Sex', 'Embarked'])\n",
    "one_hot_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91467ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set에서의 성능:  0.001504793875282643\n",
      "training set에서의 성능:  5.090741647943728\n"
     ]
    }
   ],
   "source": [
    "# 과소적합 방지만 생각해보자!\n",
    "# 과소적합은 모델이 너무 간단해서 데이터의 관계를 잘 학습하지 못하는 현상이다\n",
    "# 과소적합을 막기 위해서는 충분히 복잡한 모델을 사용하는 것이다.\n",
    "# 복잡한 모델의 의미는 선형회귀보다는 다항회귀 사용 등\n",
    "\n",
    "# 대학원 합격 데이터 (학생 아이디같은 Serial No 컬럼 안 써서 미리 삭제)\n",
    "admission_df = pd.read_csv('./admission_data.csv').drop('Serial No.', axis=1) # axis=1 열기준\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "admission_df.head()\n",
    "\n",
    "# 입력변수 정의\n",
    "X = admission_df.drop(['Chance of Admit '], axis=1) # 합격률 제외 모든 컬럼 넣어서 입력변수 따로 저장\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(6) # 6차항 변형기 정의\n",
    "polynomial_features = polynomial_transformer.fit_transform(X.values) # 인풋 데이터를 넣어서 변수를 좀 더 높은 차항으로 변형\n",
    "features = polynomial_transformer.get_feature_names(X.columns) # 변수 이름 생성\n",
    "\n",
    "X = pd.DataFrame(polynomial_features, columns=features) # 변환된 내용들 입력변수 데이터프레임에 다시 저장\n",
    "X.head()\n",
    "\n",
    "# 목표변수 정의\n",
    "y = admission_df[['Chance of Admit ']]\n",
    "y.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_predict)\n",
    "print(\"training set에서의 성능: \", sqrt(train_mse))\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_predict)\n",
    "print(\"training set에서의 성능: \", sqrt(test_mse))\n",
    "\n",
    "# 훈련에서는 0에 가까운 엄청 좋은 결과가 나옴, 학습 굿굿으로 과소적합을 막음\n",
    "# 근데 테스트 보면 높은 오차가 나옴, 과적합이 됐음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c708ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set에서의 성능:  0.06336620966147144\n",
      "training set에서의 성능:  0.06007719092689257\n"
     ]
    }
   ],
   "source": [
    "# 위에거 복붙하고 모델만 수정!\n",
    "admission_df = pd.read_csv('./admission_data.csv').drop('Serial No.', axis=1) # axis=1 열기준\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "admission_df.head()\n",
    "\n",
    "# 입력변수 정의\n",
    "X = admission_df.drop(['Chance of Admit '], axis=1) # 합격률 제외 모든 컬럼 넣어서 입력변수 따로 저장\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(6) # 6차항 변형기 정의\n",
    "polynomial_features = polynomial_transformer.fit_transform(X.values) # 인풋 데이터를 넣어서 변수를 좀 더 높은 차항으로 변형\n",
    "features = polynomial_transformer.get_feature_names(X.columns) # 변수 이름 생성\n",
    "\n",
    "X = pd.DataFrame(polynomial_features, columns=features) # 변환된 내용들 입력변수 데이터프레임에 다시 저장\n",
    "X.head()\n",
    "\n",
    "# 목표변수 정의\n",
    "y = admission_df[['Chance of Admit ']]\n",
    "y.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "\n",
    "# L1 정규화에서 항에 람다 상수를 곱함, 세타 값이 커지는 것ㅇ 대해 얼만큼의 패널티를 줄지 정하는 변수임\n",
    "# 여기서 그 람다의 역할을 하는 파라미터는 알파(alpha)임, 알파를 0.001로 설정\n",
    "# Lasso는 손실 함수를 최소화하기 위해 경사하강법을 사용, 경사하강 최대 몇 번인지 설정(1000으로 설정함)\n",
    "# 데이터 피처 스케일링을 해주면 경사하강법으로 극소점을 더 빨리 찾을 수 있음.\n",
    "# Lasso 모델은 자체적으로 피처 스케일링을 해줄 수 있음\n",
    "# 옵셔널 파라미터로 normalize=True하면 모델 학습 전에 자동으로 인풋 데이터를 0과 1 사이의 숫자로 노멀라이즈해줌\n",
    "model = Lasso(alpha=0.001, max_iter=1000, normalize=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_predict)\n",
    "print(\"training set에서의 성능: \", sqrt(train_mse))\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_predict)\n",
    "print(\"training set에서의 성능: \", sqrt(test_mse))\n",
    "\n",
    "# 훈련에서는 0에 가까운 엄청 좋은 결과가 나옴, 학습 굿굿으로 과소적합을 막음\n",
    "# 근데 테스트 보면 높은 오차가 나옴, 과적합이 됐음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479fd135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 경고 메시지 출력 막는 코드\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "iris_data = datasets.load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = pd.DataFrame(iris_data.target, columns=['Class'])\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# k겹 교차 검증을 할 모델, 입력변수, 목표변수(values.ravel()이 경고메시지 막아줌), cv는 k수(지금은 5겹 교차 검증)\n",
    "# np.average로 5개 교차검증에 대한 성능 리턴\n",
    "np.average(cross_val_score(logistic_model, X, y.values.ravel(), cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b8b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3941909193594558, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6665613729611939, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7480640336871544, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6471628588582568, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7306575352344421, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.37162160050393483, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6288326239067981, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7122008672364186, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6113927019931451, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6901899825227322, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3636271555541782, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6167394489798897, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7033491980740678, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6017920529361052, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6779231024554032, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3583986339662947, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6092515587250081, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6973680770381776, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5953554653015733, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6699215850438313, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.35457585358268856, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6034986909799318, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6926296641379236, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5905355947654967, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.663624201021256, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39481620406072077, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.661004913889271, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7381780718896991, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6385793703801849, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7216200157856394, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.37778602483156504, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6388951165044905, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7187986725766646, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6172952472544712, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.69698599261246, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3706101364740209, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.628849565439817, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7118357028169685, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6096334786939342, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.687577621324159, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3660128355378915, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6216733028105308, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7069087054200359, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6048054487523169, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6812924496476419, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3625356995360615, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6160611125920897, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7029460343220442, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6009893225098092, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6761719656376093, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4056248691358118, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6767160396395058, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.751652519018266, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6515805136557029, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.734348933366113, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3847765834561257, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6535536509141936, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.731168121945896, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6320519963137723, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.710458251876838, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.375896379512873, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6421511096662287, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7221826094600828, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6237893883534819, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7007276296985164, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.37181444233701477, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.633185857776733, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7147405489485296, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.617225330789204, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6931316795554777, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.36878290565737154, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.628831511807555, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7107304678329243, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.611259593790767, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6862756707816541, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4056085572545014, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6818130864496449, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7551151800584972, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.659000429455708, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7391572806338825, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3889173363956406, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.657410085320736, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7310855858522132, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6327300590994209, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7113756589312197, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.38329453574761596, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6497170707948473, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7244845022216193, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6237876849852213, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7015759606137676, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3801248979223824, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6451812040808597, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7213874403483479, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6198059318478797, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6969926987655997, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3777540178747575, tolerance: 0.0006706039000000001\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6418372353397257, tolerance: 0.0008245817750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7190266352765878, tolerance: 0.0008590157750000003\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6173903761637544, tolerance: 0.0007997223999999996\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6939479123706317, tolerance: 0.0008114630999999998\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/oow214/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8295309248223048, tolerance: 0.0009940386200000004\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'max_iter': 100}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso 모델로 그리드 서치\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "\n",
    "admission_df = pd.read_csv('./admission_data.csv').drop('Serial No.', axis=1) # axis=1 열기준\n",
    "\n",
    "admission_df.head()\n",
    "\n",
    "# 입력변수 정의\n",
    "X = admission_df.drop(['Chance of Admit '], axis=1) # 합격률 제외 모든 컬럼 넣어서 입력변수 따로 저장\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(6) # 6차항 변형기 정의\n",
    "polynomial_features = polynomial_transformer.fit_transform(X.values) # 인풋 데이터를 넣어서 변수를 좀 더 높은 차항으로 변형\n",
    "features = polynomial_transformer.get_feature_names(X.columns) # 변수 이름 생성\n",
    "\n",
    "X = pd.DataFrame(polynomial_features, columns=features) # 변환된 내용들 입력변수 데이터프레임에 다시 저장\n",
    "X.head()\n",
    "\n",
    "# 목표변수 정의\n",
    "y = admission_df[['Chance of Admit ']]\n",
    "y.head()\n",
    "\n",
    "hyper_parameter = { # 하이퍼파라미터로 실험해보고싶은 값을 넣는다. 이중 어떤 조합으로 모델을 학습시키는게 좋은지 확인한다.\n",
    "    'alpha' : [0.01, 0.1, 1, 10],\n",
    "    'max_iter' : [100, 500, 1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "lasso_model = Lasso() # 이때는 옵셔널 파라미터 하나도 안 넣는다\n",
    "\n",
    "# 모델, 실험할 하이퍼 파라미터 값, 몇 겹 교차 검증을 할지 입력\n",
    "hyper_parameter_turner = GridSearchCV(lasso_model, hyper_parameter, cv=5)\n",
    "hyper_parameter_turner.fit(X, y)\n",
    "\n",
    "# 경고는 맥스 이터 값이 충분하지 않은 모델이 있었다는 내용이다 (원하는 최적값 찾을 수 없다)\n",
    "\n",
    "hyper_parameter_turner.best_params_\n",
    "# 알파는 1, 맥스 이터는 100일 때 가장 좋다고 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4891869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 0 2 2 0 2 0 1 1 1 2 2 0 0 2 2 0 0 1 2 0 1 1 2 1 1 1 2]\n",
      "0.8666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 분류 데이터셋 iris\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris_data = load_iris()\n",
    "# print(iris_data.DESCR) # 꽃받침(sepal)과 꽃잎(petal) 길이와 너비\n",
    "\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = pd.DataFrame(iris_data.target, columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) \n",
    "\n",
    "# 결정 트리의 최대 깊이(얼마나 깊은 트리를 만들지)를 설정한다, 옵션임\n",
    "model = DecisionTreeClassifier(max_depth=4) \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict(X_test))\n",
    "\n",
    "print(model.score(X_test, y_test)) # 모델 평가, 93% 확률로 제대로 분류했다\n",
    "\n",
    "importances = model.feature_importances_ # 속성별 중요도 저장\n",
    "\n",
    "indices_sorted = np.argsort(importances) # 중요도 정렬\n",
    "\n",
    "# 시각화\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(importances)), importances[indices_sorted])\n",
    "plt.xticks(range(len(importances)), X.columns[indices_sorted], rotation=90)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ec0639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris_data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = pd.DataFrame(iris_data.target, columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) \n",
    "y_train = y_train.values.ravel() # 모델 학습할 때 경고 안 뜨게 하는 코드\n",
    "\n",
    "# n_estimators는 결정 트리를 몇 개 만들어서 예측할 것인지 정해주는 변수 (안 쓰면 기본 값이 10)\n",
    "# max_depth 트리의 최대 깊이 설정 (랜덤포레스트가 만드는 모든 트리의 최개 딮이 지정)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "importances = model.feature_importances_ # 속성별 중요도 저장\n",
    "\n",
    "indices_sorted = np.argsort(importances) # 중요도 정렬\n",
    "\n",
    "# 시각화\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(importances)), importances[indices_sorted])\n",
    "plt.xticks(range(len(importances)), X.columns[indices_sorted], rotation=90)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b32bde06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 0 2 2 0 2 0 1 1 1 2 2 0 0 2 2 0 0 1 2 0 1 1 2 1 1 1 2]\n",
      "0.8666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris_data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = pd.DataFrame(iris_data.target, columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) \n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.predict(X_test))\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# 에다부스트도 결정트리라 평균 지니 감소를 이용해 속성 중요도 계산 가능\n",
    "importances = model.feature_importances_ # 속성별 중요도 저장\n",
    "\n",
    "indices_sorted = np.argsort(importances) # 중요도 정렬\n",
    "\n",
    "# 시각화\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(importances)), importances[indices_sorted])\n",
    "plt.xticks(range(len(importances)), X.columns[indices_sorted], rotation=90)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7bd61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
